<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Introduction</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>





</head>

<body>
<p>This document describes the data layout and dataelements of the file &ldquo;uci_har_get_clean_summary.csv&rdquo;</p>

<h2>Introduction</h2>

<p>The dataset delivered by <a href="www.smartlab.ws">Smartlab</a> as produced by the Human Activity Recognition study(HAR) is retrieved at <a href="https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip">Data location</a>. Forementioned dataset is then further processed, see <a href="https://github.com/siggy4711/getting_cleaning_data/blob/master/README.md">README.md</a> for a description of the processing.</p>

<p>The data in the file uci_har_get_clean_summary.csv records the average of feature observations per subject/activity group. There are 30 subjects and each subject performs one of 6 activities so there are 30*6 = 180 groups(rows). There are 66 feature averages per group so a single row contains 68 values, these are the subject, the activity and the 66 feature averages.</p>

<h3>File structure</h3>

<p>run_analysis.R will output &ldquo;uci_har_get_clean_summary.csv&rdquo;, stored in working directory,format:</p>

<ul>
<li>first row has columnnames</li>
<li>separator is &ldquo;,&rdquo;</li>
<li>dimensions are 180 rows 68 columns.The columns consist of subject,activity and 66 features. The rows contain the normalised average(between [-1,1]) of the 66 features per subject per activity, there are 30 subject each performing 6 activities totaling to 180 rows.</li>
<li>size 220 kB</li>
</ul>

<h2>Featurenames</h2>

<p>In the dataset of the HAR study the featurenames are provided in the file features.txt, a description is given in features_info.txt. The HAR study delivers a featurevector of 561 elements, as a requirement, of the 561 feature vector only features with &ldquo;mean()&rdquo; and &ldquo;std()&rdquo; in their name are kept when constructing &ldquo;uci_har_get_clean_summary.csv&rdquo;, the kept features contain the measurements on the mean and standard deviation(over a timewindow), 66 features are kept.</p>

<p>I slightly adapted the explanation from the HAR study, quoted text in <em>italic</em>, taken from file features_info.txt the taxonomy of the feature names:</p>

<p><em>The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix &#39;t&#39; to denote time) were captured at a constant rate of 50 Hz.</em><br/>
<em>The acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ)</em><br/>
<em>The body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ).</em><br/>
<em>Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag).</em><br/>
<em>Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the &#39;f&#39; to indicate frequency domain signals).</em></p>

<p><em>These signals were used to estimate variables of the feature vector for each pattern:</em><br/>
<em>&#39;-XYZ&#39; is used to denote 3-axial signals in the X, Y and Z directions.</em></p>

<p><em>tBodyAcc-XYZ</em><br/>
<em>tGravityAcc-XYZ</em><br/>
<em>tBodyAccJerk-XYZ</em><br/>
<em>tBodyGyro-XYZ</em><br/>
<em>tBodyGyroJerk-XYZ</em><br/>
<em>tBodyAccMag</em><br/>
<em>tGravityAccMag</em><br/>
<em>tBodyAccJerkMag</em><br/>
<em>tBodyGyroMag</em><br/>
<em>tBodyGyroJerkMag</em><br/>
<em>fBodyAcc-XYZ</em><br/>
<em>fBodyAccJerk-XYZ</em><br/>
<em>fBodyGyro-XYZ</em><br/>
<em>fBodyAccMag</em><br/>
<em>fBodyAccJerkMag</em><br/>
<em>fBodyGyroMag</em><br/>
<em>fBodyGyroJerkMag</em>  </p>

<p><em>The set of variables that were estimated from these signals are:</em>
**
<em>mean(): Mean value</em><br/>
<em>std(): Standard deviation</em><br/>
<em>plus some more which are not relevant</em>  </p>

<p>The featurenames from the HAR study are slightly adjusted, for better usuability in R, &ldquo;()&rdquo; is removed and &ldquo;-&rdquo; is replaced by &ldquo;_&rdquo;, eg tBodyAcc-mean()-X is changed to  tBodyAcc_mean_X. Further &ldquo;avg_&rdquo; is prefixed for the featurename to indicate that the delivered value is an average. No further adjustment is done to keep the names as close as possible to the original names who are already descriptive.</p>

<p>Examples, from the featurenames of &ldquo;uci_har_get_clean_summary.csv&rdquo;<br/>
&ldquo;avg_tBodyAcc_mean_X&rdquo;: avg for average, t prefix(after avg_) means time domain, BodyAcc is acceleration body part, mean is the estimated mean from the signals(over a small time period), X is the X-axis<br/>
avg_fBodyAcc_std_Y: avg for average,f prefix(after avg_) means frequency domain, BodyAcc is acceleration body part, std is the estimated standard deviation from the signals(over a small time period), Y is the Y-axis</p>

<p>Note: the semantics for features containing fBodyBody in the name are not given, probably one body too much. Nonetheless these featurenames are kept as is.</p>

<p>For the &ldquo;uci_har_get_clean_summary.csv&rdquo; file all feature observations are grouped by subject and activity, and for every feature(of 66) the average per group is calculated.</p>

<h2>Datadictionary &ldquo;uci_har_get_clean_summary.csv&rdquo;</h2>

<p>The following columns(variables) are recorded in the same sequence as below.</p>

<p>subject:<br/>
person performing activity at feature observation
integer in range 1 to 30</p>

<p>activity:<br/>
activity performed at feature observation</p>

<ul>
<li>WALKING</li>
<li>WALKING_UPSTAIRS</li>
<li>WALKING_DOWNSTAIRS</li>
<li>SITTING</li>
<li>STANDING</li>
<li>LAYING</li>
</ul>

<p>Features:<br/>
The features are of type decimal between [-1,1] eg -0.928444801702128<br/>
avg_tBodyAcc_mean_X<br/>
avg_tBodyAcc_mean_Y<br/>
avg_tBodyAcc_mean_Z<br/>
avg_tBodyAcc_std_X<br/>
avg_tBodyAcc_std_Y<br/>
avg_tBodyAcc_std_Z<br/>
avg_tGravityAcc_mean_X<br/>
avg_tGravityAcc_mean_Y<br/>
avg_tGravityAcc_mean_Z<br/>
avg_tGravityAcc_std_X<br/>
avg_tGravityAcc_std_Y<br/>
avg_tGravityAcc_std_Z<br/>
avg_tBodyAccJerk_mean_X<br/>
avg_tBodyAccJerk_mean_Y<br/>
avg_tBodyAccJerk_mean_Z<br/>
avg_tBodyAccJerk_std_X<br/>
avg_tBodyAccJerk_std_Y<br/>
avg_tBodyAccJerk_std_Z<br/>
avg_tBodyGyro_mean_X<br/>
avg_tBodyGyro_mean_Y<br/>
avg_tBodyGyro_mean_Z<br/>
avg_tBodyGyro_std_X<br/>
avg_tBodyGyro_std_Y<br/>
avg_tBodyGyro_std_Z<br/>
avg_tBodyGyroJerk_mean_X<br/>
avg_tBodyGyroJerk_mean_Y<br/>
avg_tBodyGyroJerk_mean_Z<br/>
avg_tBodyGyroJerk_std_X<br/>
avg_tBodyGyroJerk_std_Y<br/>
avg_tBodyGyroJerk_std_Z<br/>
avg_tBodyAccMag_mean<br/>
avg_tBodyAccMag_std<br/>
avg_tGravityAccMag_mean<br/>
avg_tGravityAccMag_std<br/>
avg_tBodyAccJerkMag_mean<br/>
avg_tBodyAccJerkMag_std<br/>
avg_tBodyGyroMag_mean<br/>
avg_tBodyGyroMag_std<br/>
avg_tBodyGyroJerkMag_mean<br/>
avg_tBodyGyroJerkMag_std<br/>
avg_fBodyAcc_mean_X<br/>
avg_fBodyAcc_mean_Y<br/>
avg_fBodyAcc_mean_Z<br/>
avg_fBodyAcc_std_X<br/>
avg_fBodyAcc_std_Y<br/>
avg_fBodyAcc_std_Z<br/>
avg_fBodyAccJerk_mean_X<br/>
avg_fBodyAccJerk_mean_Y<br/>
avg_fBodyAccJerk_mean_Z<br/>
avg_fBodyAccJerk_std_X<br/>
avg_fBodyAccJerk_std_Y<br/>
avg_fBodyAccJerk_std_Z<br/>
avg_fBodyGyro_mean_X<br/>
avg_fBodyGyro_mean_Y<br/>
avg_fBodyGyro_mean_Z<br/>
avg_fBodyGyro_std_X<br/>
avg_fBodyGyro_std_Y<br/>
avg_fBodyGyro_std_Z<br/>
avg_fBodyAccMag_mean<br/>
avg_fBodyAccMag_std<br/>
avg_fBodyBodyAccJerkMag_mean<br/>
avg_fBodyBodyAccJerkMag_std<br/>
avg_fBodyBodyGyroMag_mean<br/>
avg_fBodyBodyGyroMag_std<br/>
avg_fBodyBodyGyroJerkMag_mean<br/>
avg_fBodyBodyGyroJerkMag_std  </p>

</body>

</html>

